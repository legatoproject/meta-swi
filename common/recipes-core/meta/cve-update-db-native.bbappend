
python do_fetch() {
    """
    Update NVD database with json data feed
    """
    import bb.utils
    import bb.progress
    import sqlite3, urllib, urllib.parse, shutil, gzip
    from datetime import date

    bb.utils.export_proxies(d)

    nvd_mirror = d.getVar("CVE_NVD_MIRROR_URL", True)
    if nvd_mirror:
        BASE_URL = "%s/feeds/json/cve/1.1/nvdcve-1.1-" % nvd_mirror
    else:
        BASE_URL = "https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-"
    YEAR_START = 2002

    db_file = d.getVar("CVE_CHECK_DB_FILE")
    db_dir = os.path.dirname(db_file)

    if os.path.exists("{0}-journal".format(db_file)):
        # If a journal is present the last update might have been interrupted. In that case,
        # just wipe any leftovers and force the DB to be recreated.
        os.remove("{0}-journal".format(db_file))

        if os.path.exists(db_file):
            os.remove(db_file)

    # The NVD database changes once a day, so no need to update more frequently
    # Allow the user to force-update
    try:
        import time
        update_interval = int(d.getVar("CVE_DB_UPDATE_INTERVAL"))
        if update_interval < 0:
            bb.note("CVE database update skipped")
            return
        if time.time() - os.path.getmtime(db_file) < update_interval:
            return

    except OSError:
        pass

    bb.utils.mkdirhier(db_dir)

    # Connect to database
    conn = sqlite3.connect(db_file)
    c = conn.cursor()

    initialize_db(c)

    def clean_up():
        conn.commit()
        conn.close()

    def fetch_url(url):
        """Provide a more robust version of urllib.request.urlopen."""
        max_retry = 3
        count = 0
        while count < max_retry:
            count += 1
            try:
                response = urllib.request.urlopen(url)
                if response:
                    return response
            except urllib.error.URLError as e:
                cve_f.write('warning: cve db update error, unable to fetch cve data %s (try %d).\n\n' % (url, count))
                bb.warn("failed to fetch cve data @ %s (try %d, %s)" % (url, count, e.reason))
                if count == max_retry:
                    # Max retry count reach, reraise
                    raise
                else:
                    # Wait 5 seconds before next retry
                    time.sleep(5)
        return None

    with bb.progress.ProgressHandler(d) as ph, open(os.path.join(d.getVar("TMPDIR"), 'cve_check'), 'a') as cve_f:
        total_years = date.today().year + 1 - YEAR_START
        for i, year in enumerate(range(YEAR_START, date.today().year + 1)):
            ph.update((float(i + 1) / total_years) * 100)
            year_url = BASE_URL + str(year)
            meta_url = year_url + ".meta"
            json_url = year_url + ".json.gz"

            # Retrieve meta last modified date
            try:
                response = fetch_url(meta_url)
            except urllib.error.URLError as e:
                cve_f.write('Warning: CVE db update error, Unable to fetch CVE data.\n\n')
                bb.warn("Failed to fetch CVE data (%s)" % e.reason)
                clean_up()
                return

            if response:
                for l in response.read().decode("utf-8").splitlines():
                    key, value = l.split(":", 1)
                    if key == "lastModifiedDate":
                        last_modified = value
                        break
                else:
                    bb.warn("Cannot parse CVE metadata, update failed")
                    clean_up()
                    return

            # Compare with current db last modified date
            c.execute("select DATE from META where YEAR = ?", (year,))
            meta = c.fetchone()
            if not meta or meta[0] != last_modified:
                # Clear products table entries corresponding to current year
                c.execute("delete from PRODUCTS where ID like ?", ('CVE-%d%%' % year,))

                # Update db with current year json file
                try:
                    response = fetch_url(json_url)
                    if response:
                        update_db(c, gzip.decompress(response.read()).decode('utf-8'))
                    c.execute("insert or replace into META values (?, ?)", [year, last_modified])
                except urllib.error.URLError as e:
                    cve_f.write('Warning: CVE db update error, CVE data is outdated.\n\n')
                    bb.warn("Cannot parse CVE data (%s), update failed" % e.reason)
                    clean_up()
                    return

            # Update success, set the date to cve_check file.
            if year == date.today().year:
                cve_f.write('CVE database update : %s\n\n' % date.today())

        clean_up()
}

